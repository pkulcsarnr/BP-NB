{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "2019-03-22 19:06\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from nltk.stem import PorterStemmer\n",
    "from os import listdir\n",
    "\n",
    "class Regs: \n",
    "    specialChars = '' \n",
    "    digits = '' \n",
    "    singleChars = ''\n",
    "    multipleWhiteSpaces = ''\n",
    "    stopWords = list()\n",
    "stopWords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\"ers\", \"yourself\", \"yourselves\", \"he\",\"isnt\",\"cant\" \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"wasnt\", \"were\", \"be\", \"been\", \"being\", \"have\", \"havent\", \"has\", \"had\", \"having\", \"do\", \"does\", \"doesnt\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#Precompile regexes for better performance\n",
    "def compileRegexes():\n",
    "    regexes = Regs()\n",
    "    regexes.specialChars = re.compile('[^\\w\\s]')\n",
    "    regexes.digits = re.compile('\\d')\n",
    "    regexes.singleChars = re.compile('\\s.\\s')\n",
    "    regexes.multipleWhiteSpaces = re.compile('[ ]{2,}')\n",
    "    for sw in stopWords:\n",
    "        exp = '\\\\b' + sw + '+\\W'\n",
    "        regexes.stopWords.append(re.compile(exp))\n",
    "    return(regexes)\n",
    "\n",
    "#Format the index into string with length 7\n",
    "def formatIndex(index):\n",
    "    i = str(index)\n",
    "    while len(i) < 7:\n",
    "        i = \"0\" + i\n",
    "    return(i)\n",
    "\n",
    "#Gather the texts from the source, based on starting index, amount of article and class\n",
    "#=> returns array of texts and array of classes\n",
    "def gatherTexts(startingIndex, amountOfArticles, includeClasses):\n",
    "    if len(includeClasses) < 1:\n",
    "        print(\"There must be at least 1 class. eg: [0,1,2]\")\n",
    "    \n",
    "    #Create two arrays, which will be returned from this function\n",
    "    texts = []\n",
    "    types = []\n",
    "    \n",
    "    #Get data for class 0 => in our project it is FINANCE\n",
    "    if 0 in includeClasses:\n",
    "        articles = listdir(\"DATA/Finance\")\n",
    "        nArticles = len(articles)\n",
    "        #check if there are enough articles for the input paramteres\n",
    "        if (nArticles > startingIndex + amountOfArticles) :\n",
    "            for ind in range(startingIndex, startingIndex + amountOfArticles):\n",
    "                with open(\"DATA/Finance/news_\" + formatIndex(ind) + \".json\", encoding=\"utf8\") as json_data:\n",
    "                    texts.append(json.load(json_data)[\"text\"])\n",
    "                    types.append(\"0\")   \n",
    "\n",
    "    #Get data for class 1 => in our project it is SPORT\n",
    "    if 1 in includeClasses:\n",
    "        articles = listdir(\"DATA/Sports\")\n",
    "        nArticles = len(articles)\n",
    "        #check if there are enough articles for the input paramteres\n",
    "        if (nArticles > startingIndex + amountOfArticles) :\n",
    "            for ind in range(startingIndex, startingIndex + amountOfArticles):\n",
    "                with open(\"DATA/Sports/news_\" + formatIndex(ind) + \".json\", encoding=\"utf8\") as json_data:\n",
    "                    texts.append(json.load(json_data)[\"text\"])\n",
    "                    types.append(\"1\")   \n",
    "                    \n",
    "    #Get data for class 2 => in our project it is TECHNOLOGY\n",
    "    if 2 in includeClasses:\n",
    "        articles = listdir(\"DATA/Technology\")\n",
    "        nArticles = len(articles)\n",
    "        #check if there are enough articles for the input paramteres\n",
    "        if (nArticles > startingIndex + amountOfArticles) :\n",
    "            for ind in range(startingIndex, startingIndex + amountOfArticles):\n",
    "                with open(\"DATA/Technology/news_\" + formatIndex(ind) + \".json\", encoding=\"utf8\") as json_data:\n",
    "                    texts.append(json.load(json_data)[\"text\"])\n",
    "                    types.append(\"2\")   \n",
    "                    \n",
    "    #Get data for class 3 => in our project it is ENTERTAINMENT\n",
    "    if 3 in includeClasses:\n",
    "        articles = listdir(\"DATA/Entertainment\")\n",
    "        nArticles = len(articles)\n",
    "        #check if there are enough articles for the input paramteres\n",
    "        if (nArticles > startingIndex + amountOfArticles) :\n",
    "            for ind in range(startingIndex, startingIndex + amountOfArticles):\n",
    "                with open(\"DATA/Entertainment/news_\" + formatIndex(ind) + \".json\", encoding=\"utf8\") as json_data:\n",
    "                    texts.append(json.load(json_data)[\"text\"])\n",
    "                    types.append(\"3\") \n",
    "                    \n",
    "    #if not (regexes is None):\n",
    "    #    print(\"doing preprocess stage1\")\n",
    "    #    for j, text in enumerate(texts, start=0):\n",
    "    #        texts[j] = preprocessStageOne(text, regexes)\n",
    "                    \n",
    "    return {'texts':texts, 'types':types}\n",
    "\n",
    "def preprocessTexts(texts,types, regexes, usePorterStemmer = 0, removeUnfrequent = 0, removeFrequent = 0):    \n",
    "    articles = []\n",
    "    for index, text in enumerate(texts, start=0):\n",
    "        if(text):\n",
    "            articles.append(preprocessArticle(text,regexes,usePorterStemmer))\n",
    "        if( index % 250 == 0):\n",
    "            print(\"Preprocessed texts:\",index)\n",
    "        \n",
    "    #create one array fromm all articles\n",
    "    words = []\n",
    "    words = [item for sublist in articles for item in sublist]\n",
    "    #remove duplicate values from words list\n",
    "    words = list(set(words))\n",
    "    words = sorted(words)\n",
    "    wordsDictionary = dict((v, i) for i, v in enumerate(words))\n",
    "    \n",
    "    articleWords = np.zeros((len(articles), len(words) + 1))\n",
    "    for index, article in enumerate(articles, start=0):\n",
    "        articleWords[index, 0 ] = types[index] \n",
    "        for j, word in enumerate(article, start=0):\n",
    "            if word != '':\n",
    "                articleWords[index, wordsDictionary[word] + 1] = 1   \n",
    "                \n",
    "    #Remove words with occurance = removeUnfrequent\n",
    "    if removeUnfrequent >= 1:    \n",
    "        indexes = []\n",
    "        for word in wordsDictionary:\n",
    "            if(sum(articleWords[:,wordsDictionary[word]]) > removeUnfrequent):\n",
    "                indexes.append(wordsDictionary[word])\n",
    "        ind = np.array(indexes)\n",
    "        words = np.array(words)\n",
    "        words = words[ind].tolist()\n",
    "        articleWords = articleWords[:,np.insert(ind + 1, 0,0, axis=0)]\n",
    "    \n",
    "    #Remove words, which are the most frequent => TOP removeFrequent will be removed\n",
    "    if removeFrequent > 0:\n",
    "        usage = np.zeros(len(words)+1)\n",
    "        for i in range(1, len(words)+1):\n",
    "            usage[i] = sum(articleWords[:,i])\n",
    "        for i in range(0, removeFrequent):\n",
    "            words = np.delete(words,usage.tolist().index(max(usage)),0)\n",
    "            articleWords = np.delete(articleWords, usage.tolist().index(max(usage)),1)\n",
    "            usage = np.delete(usage,usage.tolist().index(max(usage)),0)\n",
    "            \n",
    "    return{'articleWords':articleWords, 'words':words}\n",
    "\n",
    "\n",
    "#Create matrix containg all Phi values\n",
    "#returns array(nClasses x amountOfWords)\n",
    "def createPhiMatrix(articleWords, includeClasses):\n",
    "    numberOfClasses = len(includeClasses)\n",
    "    Y = np.zeros((numberOfClasses, articleWords.shape[1]))\n",
    "    \n",
    "    sumClasses = np.zeros((numberOfClasses))\n",
    "    #number of rows clasified to first / second group\n",
    "    for c, index in enumerate(includeClasses, start = 0):\n",
    "        sumClasses[index] = float(len(articleWords[articleWords[:,0] == c,0]))\n",
    "\n",
    "    #Laplace => alfa = 1\n",
    "    alfa = 1\n",
    "\n",
    "    #calcualting Phi_{y=0} and Phi_{y=1}\n",
    "    for j in range(0, numberOfClasses):\n",
    "        Y[j,0] = (sumClasses[j] + alfa) / float(articleWords.shape[0] + numberOfClasses * alfa)\n",
    "\n",
    "    for j in range(1, articleWords.shape[1]):\n",
    "        #calcualting Phi_{j|y=0} and Phi_{j|y=1}\n",
    "        for k in range(0, numberOfClasses):\n",
    "            Y[k,j] = (np.sum(articleWords[articleWords[:,0]==includeClasses[k],j]) + alfa) / (sumClasses[k] + numberOfClasses * alfa)\n",
    "    \n",
    "    return(Y)\n",
    "    \n",
    "#Preprocess the article with the precompiled regexes, and optional stemmer \n",
    "#=> returns the text splitted into array of words\n",
    "def preprocessArticle(text, regexes, usePorterStemmer):\n",
    "    text = preprocessStageOne(text, regexes)\n",
    "    if usePorterStemmer == 1:\n",
    "        splitted = text.split()\n",
    "        for index, word in enumerate(splitted, start=0):\n",
    "            splitted[index] = ps.stem(word)\n",
    "        return splitted\n",
    "    return(text.split())\n",
    "\n",
    "def preprocessStageOne(text, regexes):\n",
    "    text = text.lower()\n",
    "    #new lines\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('_', ' ')\n",
    "    #special characters\n",
    "    text = re.sub(regexes.specialChars, ' ', text)\n",
    "    #digits\n",
    "    text = re.sub(regexes.digits, '', text)\n",
    "    #stopwords\n",
    "    for sw in regexes.stopWords:\n",
    "        text = re.sub(sw , '', text)\n",
    "    #single characters (ex donald j trump => donald trump)\n",
    "    text = re.sub(regexes.singleChars, ' ', text)\n",
    "    #multiple white spaces\n",
    "    text = re.sub(regexes.multipleWhiteSpaces, ' ', text)\n",
    "    return text\n",
    "\n",
    "#Make prediction based on \n",
    "def predict(phiMatrix, text,words, regexes, usePorterStemmer):\n",
    "    nClasses = phiMatrix.shape[0]\n",
    "    Y = phiMatrix\n",
    "    textPorcessed = preprocessArticle(text,regexes,usePorterStemmer)\n",
    "    testArticleWords = np.zeros((1, len(words)))\n",
    "    for k, word in enumerate(textPorcessed, start=0):\n",
    "            if word in words:\n",
    "                testArticleWords[0, words.index(word)] = 1\n",
    "\n",
    "    P = np.zeros(nClasses)\n",
    "    for j in range(0, nClasses):\n",
    "        P[j] = np.log(Y[j,0]) + ((np.log(np.array(Y[j,1:]*testArticleWords)[testArticleWords == 1]))).sum() + ((np.log(np.array((1 - Y[j,1:])*(testArticleWords - 1)*-1)[testArticleWords == 0]))).sum()\n",
    "\n",
    "    classPossibilities = np.zeros(4)\n",
    "    for i in range(0,phiMatrix.shape[0]):\n",
    "        classPossibilities[i] = 1 / (sum(np.exp(P-P[i])))\n",
    "    \n",
    "    return(np.argmax(classPossibilities))\n",
    "\n",
    "print(\"Done\")\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.015621185302734375\n"
     ]
    }
   ],
   "source": [
    "rawTexts =  gatherTexts(1,500,np.array([0,1,2,3]))\n",
    "regs = compileRegexes()\n",
    "preprocessedTexts = preprocessTexts(rawTexts[\"texts\"],rawTexts[\"types\"],regs)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "with open(\"DATA/Sport/news_0002100.json\", encoding=\"utf8\") as json_data:\n",
    "    #print(index)\n",
    "    testtext = json.load(json_data)[\"text\"]\n",
    "    start = time.time()\n",
    "    print(predict(phi,testtext,preprocessedTexts[\"words\"],regs,0))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generateTarget(amount):\n",
    "    target = np.zeros(4*amount)\n",
    "    for ind in range(amount, 2*amount):\n",
    "        target[ind] = 1\n",
    "    for ind in range(2*amount, 3*amount):\n",
    "        target[ind] = 2\n",
    "    for ind in range(3*amount, 4*amount):\n",
    "        target[ind] = 3\n",
    "    return(target)\n",
    "    \n",
    "    \n",
    "#preprocessedTexts = preprocessTexts(rawTexts[\"texts\"],rawTexts[\"types\"],regs)\n",
    "\n",
    "#preprocessedTexts[\"words\"][np.where(np.sum(preprocessedTexts[\"articleWords\"][:,1:], axis=0) == max(np.sum(preprocessedTexts[\"articleWords\"][:,1:], axis=0)))[0][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top 50 tokens in sport tweets')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_pos = np.arange(50)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(y_pos, term_freq_df.sort_values(by='sport', ascending=False)['sport'][:50], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, term_freq_df.sort_values(by='sport', ascending=False)['sport'][:50].index,rotation='vertical')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Top 50 sport tokens')\n",
    "plt.title('Top 50 tokens in sport tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance</th>\n",
       "      <th>sport</th>\n",
       "      <th>technology</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1203</td>\n",
       "      <td>719</td>\n",
       "      <td>1156</td>\n",
       "      <td>929</td>\n",
       "      <td>4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>661</td>\n",
       "      <td>323</td>\n",
       "      <td>672</td>\n",
       "      <td>477</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>754</td>\n",
       "      <td>372</td>\n",
       "      <td>589</td>\n",
       "      <td>377</td>\n",
       "      <td>2092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>587</td>\n",
       "      <td>215</td>\n",
       "      <td>608</td>\n",
       "      <td>391</td>\n",
       "      <td>1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>490</td>\n",
       "      <td>331</td>\n",
       "      <td>408</td>\n",
       "      <td>411</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>274</td>\n",
       "      <td>175</td>\n",
       "      <td>275</td>\n",
       "      <td>168</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>238</td>\n",
       "      <td>104</td>\n",
       "      <td>198</td>\n",
       "      <td>164</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>223</td>\n",
       "      <td>119</td>\n",
       "      <td>196</td>\n",
       "      <td>154</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>229</td>\n",
       "      <td>79</td>\n",
       "      <td>224</td>\n",
       "      <td>126</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>177</td>\n",
       "      <td>100</td>\n",
       "      <td>145</td>\n",
       "      <td>153</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>122</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>140</td>\n",
       "      <td>95</td>\n",
       "      <td>128</td>\n",
       "      <td>111</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>149</td>\n",
       "      <td>57</td>\n",
       "      <td>131</td>\n",
       "      <td>76</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>131</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      finance  sport  technology  entertainment  total\n",
       "the      1203    719        1156            929   4007\n",
       "and       661    323         672            477   2133\n",
       "to        754    372         589            377   2092\n",
       "of        587    215         608            391   1801\n",
       "in        490    331         408            411   1640\n",
       "for       274    175         275            168    892\n",
       "that      238    104         198            164    704\n",
       "on        223    119         196            154    692\n",
       "is        229     79         224            126    658\n",
       "it        177    100         145            153    575\n",
       "with      135    135         158            122    550\n",
       "by        140     95         128            111    474\n",
       "at         95    110         118            109    432\n",
       "as        149     57         131             76    413\n",
       "this      131     87          88             90    396"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "regs = compileRegexes()\n",
    "rawTexts =  gatherTexts(1,50,np.array([0,1,2,3]))\n",
    "\n",
    "target = generateTarget(50)\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "cvec.fit(rawTexts[\"texts\"])\n",
    "\n",
    "len(cvec.get_feature_names())\n",
    "\n",
    "document_matrix = cvec.transform(np.array(rawTexts[\"texts\"]))\n",
    "\n",
    "fin_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 0])\n",
    "spo_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 1])\n",
    "tech_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 2])\n",
    "ent_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 3])\n",
    "fin_tf = np.sum(fin_doc_matrix,axis=0)\n",
    "spo_tf = np.sum(spo_doc_matrix,axis=0)\n",
    "tech_tf = np.sum(tech_doc_matrix,axis=0)\n",
    "ent_tf = np.sum(ent_doc_matrix,axis=0)\n",
    "fin = np.squeeze(np.asarray(fin_tf))\n",
    "spo = np.squeeze(np.asarray(spo_tf))\n",
    "tech = np.squeeze(np.asarray(tech_tf))\n",
    "ent = np.squeeze(np.asarray(ent_tf))\n",
    "term_freq_df = pd.DataFrame([fin,spo,tech,ent],columns=cvec.get_feature_names()).transpose()\n",
    "\n",
    "term_freq_df.columns = ['finance', 'sport', 'technology', 'entertainment']\n",
    "term_freq_df['total'] = term_freq_df['finance'] + term_freq_df['sport'] + term_freq_df['technology'] + term_freq_df['entertainment']\n",
    "term_freq_df.sort_values(by='total', ascending=False).iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 3., 3.,\n",
       "       3., 3., 3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateTarget(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "39320 columns passed, passed data had 3922 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-572375bcdaf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtech\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0ment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mterm_freq_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtech\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mterm_freq_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'finance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sport'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'technology'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'entertainment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   7495\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7496\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m-> 7497\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m   7498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   7552\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7553\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m-> 7554\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m   7555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   7610\u001b[0m             raise AssertionError('{col:d} columns passed, passed data had '\n\u001b[0;32m   7611\u001b[0m                                  '{con} columns'.format(col=len(columns),\n\u001b[1;32m-> 7612\u001b[1;33m                                                         con=len(content)))\n\u001b[0m\u001b[0;32m   7613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7614\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 39320 columns passed, passed data had 3922 columns"
     ]
    }
   ],
   "source": [
    "#np.where(np.sum(preprocessedTexts[\"articleWords\"][:,1:], axis=0) == max(np.sum(preprocessedTexts[\"articleWords\"][:,1:], axis=0)))[0]\n",
    "#rawTexts\n",
    "r = np.sum(document_matrix[0:40].toarray(),axis=0)\n",
    "\n",
    "rr = np.sum(r,axis=0)\n",
    "\n",
    "\n",
    "fin_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 0])\n",
    "spo_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 1])\n",
    "tech_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 2])\n",
    "ent_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 3])\n",
    "fin_tf = np.sum(fin_doc_matrix,axis=0)\n",
    "spo_tf = np.sum(spo_doc_matrix,axis=0)\n",
    "tech_tf = np.sum(tech_doc_matrix,axis=0)\n",
    "ent_tf = np.sum(ent_doc_matrix,axis=0)\n",
    "fin = np.squeeze(np.asarray(neg_tf))\n",
    "spo = np.squeeze(np.asarray(pos_tf))\n",
    "tech = np.squeeze(np.asarray(neg_tf))\n",
    "ent = np.squeeze(np.asarray(pos_tf))\n",
    "term_freq_df = pd.DataFrame([fin,spo,tech,ent],columns=cvec.get_feature_names()).transpose()\n",
    "\n",
    "term_freq_df.columns = ['finance', 'sport', 'technology', 'entertainment']\n",
    "term_freq_df['total'] = term_freq_df['finance'] + term_freq_df['sport'] + term_freq_df['technology'] + term_freq_df['entertainment']\n",
    "term_freq_df.sort_values(by='total', ascending=False).iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "rawTexts =  gatherTexts(1,50,np.array([0,1,2,3]))\n",
    "\n",
    "target = generateTarget(50)\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "cvec.fit(rawTexts[\"texts\"])\n",
    "\n",
    "len(cvec.get_feature_names())\n",
    "\n",
    "document_matrix = cvec.transform(np.array(rawTexts[\"texts\"]))\n",
    "\n",
    "print(len(rawTexts[\"texts\"]))\n",
    "\n",
    "\n",
    "fin_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 0])\n",
    "spo_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 1])\n",
    "tech_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 2])\n",
    "ent_doc_matrix = cvec.transform(np.array(rawTexts[\"texts\"])[target == 3])\n",
    "fin_tf = np.sum(fin_doc_matrix,axis=0)\n",
    "spo_tf = np.sum(spo_doc_matrix,axis=0)\n",
    "tech_tf = np.sum(tech_doc_matrix,axis=0)\n",
    "ent_tf = np.sum(ent_doc_matrix,axis=0)\n",
    "fin = np.squeeze(np.asarray(neg_tf))\n",
    "spo = np.squeeze(np.asarray(spo_tf))\n",
    "tech = np.squeeze(np.asarray(neg_tf))\n",
    "ent = np.squeeze(np.asarray(pos_tf))\n",
    "term_freq_df = pd.DataFrame([fin,spo,tech,ent],columns=cvec.get_feature_names()).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230\n"
     ]
    }
   ],
   "source": [
    "#print(preprocessedTexts[\"articleWords\"])\n",
    "rawTexts =  gatherTexts(1,50,np.array([0,1,2,3]))\n",
    "#regs = compileRegexes()\n",
    "preprocessedTexts = preprocessTexts(rawTexts[\"texts\"],rawTexts[\"types\"],regs)\n",
    "#for i in np.array([0,1]):\n",
    "    #print(np.mean(np.sum(preprocessedTexts[\"articleWords\"][:,np.insert(np.array(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==i,1:], axis=0) != 0),0, False)][preprocessedTexts[\"articleWords\"][:,0]==i,:], axis=0)))\n",
    "    #print(np.sum(np.sum(preprocessedTexts[\"articleWords\"][:,np.insert(np.array(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==i,1:], axis=0) != 0),0, False)][preprocessedTexts[\"articleWords\"][:,0]==i,:], axis=0) == 1))\n",
    "    #print(np.sum(np.sum(preprocessedTexts[\"articleWords\"][:,np.insert(np.array(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==i,1:], axis=0) != 0),0, False)][preprocessedTexts[\"articleWords\"][:,0]==i,:], axis=0) == 2))\n",
    "    #print(np.mean(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==i,1:], axis=1)))\n",
    "\n",
    "articleWords = preprocessedTexts[\"articleWords\"]\n",
    "#print(articleWords)\n",
    "\n",
    "wordsOfGrous0 = np.sum(articleWords[articleWords[:,0] == 0,1:], axis=0)\n",
    "wordsOfGrous1 = np.sum(articleWords[articleWords[:,0] == 1,1:], axis=0)\n",
    "\n",
    "print(np.array((np.where( np.logical_and( wordsOfGrous0 > 0, wordsOfGrous1 > 0 ) ))).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a5b45285ab28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtesttext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesttext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreprocessedTexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'phi' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"DATA/Finance/news_0002010.json\", encoding=\"utf8\") as json_data:\n",
    "    #print(index)\n",
    "    testtext = json.load(json_data)[\"text\"]\n",
    "    start = time.time()\n",
    "    print(predict(phi,testtext,preprocessedTexts[\"words\"],regs,0))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5194274028629855\n",
      "98.56\n"
     ]
    }
   ],
   "source": [
    "#print(preprocessedTexts[\"articleWords\"])\n",
    "rawTexts =  gatherTexts(1,100,np.array([1]))\n",
    "regs = compileRegexes()\n",
    "preprocessedTexts = preprocessTexts(rawTexts[\"texts\"],rawTexts[\"types\"],regs)\n",
    "print(np.mean(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==1,1:], axis=0)))\n",
    "print(np.mean(np.sum(preprocessedTexts[\"articleWords\"][preprocessedTexts[\"articleWords\"][:,0]==1,1:], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPropertiesOfTrainingSet(startIndex, endIndex, usePorterStemmer = 0, removeUnfrequent = 0, removeFrequent = 0):\n",
    "    #STEPS:\n",
    "    #---1. Gather texts from all groups\n",
    "    #---2. Preprocess them\n",
    "    #---3. Create properties:\n",
    "    #------- Average number of words in the texts for each group\n",
    "    #------- Average texts where each word \n",
    "    \n",
    "    print(\"Starting the method for creating properties...\")\n",
    "    #Needed variables:    \n",
    "    regs = compileRegexes()\n",
    "    \n",
    "    #Get and preprocess texts \n",
    "    print(\"Starting the gathering of texts from \" + str(startIndex) + \" to \" + str(endIndex) + \"...\")\n",
    "    start = time.time()\n",
    "    rawTexts =  gatherTexts(startIndex,endIndex,np.array([0,1,2,3]), null)\n",
    "    end = time.time()\n",
    "    print(\"Gathering finished in \" + str(end-start) + \" ms\")\n",
    "    print(\"Starting the preprocess...\")\n",
    "    start = time.time()\n",
    "    preprocessedTexts = preprocessTexts(rawTexts[\"texts\"],rawTexts[\"types\"],regs, usePorterStemmer, removeUnfrequent, removeFrequent)\n",
    "    end = time.time()\n",
    "    print(\"Preprocessment finished in \" + str(end-start) + \" ms\")\n",
    "    \n",
    "    print(\"Starting the properties calculation for each group...\")\n",
    "    start = time.time()\n",
    "    averageAmountOfWords = np.zeros(4)\n",
    "    averageUsageOfWords = np.zeros(4)\n",
    "    amountOfRareWords1 = np.zeros(4)\n",
    "    amountOfRareWords2 = np.zeros(4)\n",
    "    totalAmountOfWords = np.zeros(4)\n",
    "    \n",
    "    articleWords = preprocessedTexts[\"articleWords\"]\n",
    "    \n",
    "    for i in np.array([0,1,2,3]):        \n",
    "        averageUsageOfWords[i] = np.mean(np.sum(articleWords[:,np.insert(np.array(np.sum(articleWords[articleWords[:,0]==i,1:], axis=0) != 0),0, False)][articleWords[:,0]==i,:], axis=0))\n",
    "        averageAmountOfWords[i] = np.mean(np.sum(articleWords[articleWords[:,0]==i,1:], axis=1))\n",
    "        amountOfRareWords1[i] = np.sum(np.sum(articleWords[:,np.insert(np.array(np.sum(articleWords[articleWords[:,0]==i,1:], axis=0) != 0),0, False)][articleWords[:,0]==i,:], axis=0) == 1)\n",
    "        amountOfRareWords2[i] = np.sum(np.sum(articleWords[:,np.insert(np.array(np.sum(articleWords[articleWords[:,0]==i,1:], axis=0) != 0),0, False)][articleWords[:,0]==i,:], axis=0) == 2)\n",
    "        totalAmountOfWords[i] = len(np.sum(articleWords[:,np.insert(np.array(np.sum(articleWords[articleWords[:,0]==i,1:], axis=0) != 0),0, False)][articleWords[:,0]==i,:], axis=0))\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Properties for each group finished in \" + str(end-start) + \" ms\")\n",
    "    \n",
    "    print(\"Starting counting the common words trough the groups...\")\n",
    "    commonWords = np.zeros((4,4))\n",
    "    start = time.time()\n",
    "    for i in np.array([0,1,2,3]):\n",
    "        for j in np.array([0,1,2,3]): \n",
    "            wordsOfGrous0 = np.sum(articleWords[articleWords[:,0] == i,1:], axis=0)\n",
    "            wordsOfGrous1 = np.sum(articleWords[articleWords[:,0] == j,1:], axis=0)\n",
    "            commonWords[i,j] = np.array((np.where( np.logical_and( wordsOfGrous0 > 0, wordsOfGrous1 > 0 ) ))).size\n",
    "    end = time.time()\n",
    "    print(\"Common words counting finished in \" + str(end-start) + \" ms\")\n",
    "\n",
    "    return{'averageAmountOfWords':averageAmountOfWords, \n",
    "           'averageUsageOfWords':averageUsageOfWords,\n",
    "           'amountOfRareWords1':amountOfRareWords1,\n",
    "           'amountOfRareWords1Percentage':amountOfRareWords1 / totalAmountOfWords,\n",
    "           'amountOfRareWords2':amountOfRareWords2,\n",
    "           'amountOfRareWords2Percentage':amountOfRareWords2 / totalAmountOfWords,\n",
    "           'totalAmountOfWords':totalAmountOfWords,\n",
    "           'commonWords':commonWords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the method for creating properties...\n",
      "Starting the gathering of texts from 1 to 50...\n",
      "Gathering finished in 1.7856512069702148 ms\n",
      "Starting the preprocess...\n",
      "Preprocessment finished in 5.527027130126953 ms\n",
      "Starting the properties calculation for each group...\n",
      "Properties for each group finished in 0.2899503707885742 ms\n",
      "Starting counting the common words trough the groups...\n",
      "Common words counting finished in 0.16361737251281738 ms\n",
      "{'averageAmountOfWords': array([192.08, 120.78, 176.78, 141.96]), 'averageUsageOfWords': array([2.01341719, 2.17074047, 1.870292  , 1.80610687]), 'amountOfRareWords1': array([3070., 1804., 3197., 2716.]), 'amountOfRareWords1Percentage': array([0.64360587, 0.64845435, 0.67647059, 0.69109415]), 'amountOfRareWords2': array([739., 374., 712., 553.]), 'amountOfRareWords2Percentage': array([0.15492662, 0.13443566, 0.15065595, 0.14071247]), 'totalAmountOfWords': array([4770., 2782., 4726., 3930.]), 'commonWords': array([[4770., 1230., 2095., 1464.],\n",
      "       [1230., 2782., 1256., 1252.],\n",
      "       [2095., 1256., 4726., 1625.],\n",
      "       [1464., 1252., 1625., 3930.]])}\n"
     ]
    }
   ],
   "source": [
    "props = createPropertiesOfTrainingSet(1,50)\n",
    "print(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the method for creating properties...\n",
      "Starting the gathering of texts from 1 to 50...\n",
      "Gathering finished in 0.19225478172302246 ms\n",
      "Starting the preprocess...\n",
      "Preprocessment finished in 5.4446494579315186 ms\n",
      "Starting the properties calculation for each group...\n",
      "Properties for each group finished in 0.17907261848449707 ms\n",
      "Starting counting the common words trough the groups...\n",
      "Common words counting finished in 0.1216425895690918 ms\n",
      "{'averageAmountOfWords': array([175.06, 114.22, 162.86, 135.04]), 'averageUsageOfWords': array([2.52466109, 2.47873264, 2.31072645, 2.11528822]), 'amountOfRareWords1': array([2002., 1400., 2161., 2025.]), 'amountOfRareWords1Percentage': array([0.57744448, 0.60763889, 0.61322361, 0.6343985 ]), 'amountOfRareWords2': array([531., 314., 561., 482.]), 'amountOfRareWords2Percentage': array([0.15315835, 0.13628472, 0.1591941 , 0.15100251]), 'totalAmountOfWords': array([3467., 2304., 3524., 3192.]), 'commonWords': array([[3467., 1145., 1742., 1373.],\n",
      "       [1145., 2304., 1184., 1189.],\n",
      "       [1742., 1184., 3524., 1488.],\n",
      "       [1373., 1189., 1488., 3192.]])}\n"
     ]
    }
   ],
   "source": [
    "props = createPropertiesOfTrainingSet(1,50,1)\n",
    "print(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the method for creating properties...\n",
      "Starting the gathering of texts from 1 to 50...\n",
      "Gathering finished in 0.15046310424804688 ms\n",
      "Starting the preprocess...\n"
     ]
    }
   ],
   "source": [
    "props = createPropertiesOfTrainingSet(1,50,1,1)\n",
    "print(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "5750\n",
      "6000\n",
      "6250\n",
      "6500\n",
      "6750\n",
      "7000\n",
      "7250\n",
      "7500\n",
      "7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                         15681\n",
       "cbs8                                      1082\n",
       "Reuters                                    956\n",
       "news24.com                                 763\n",
       "admin                                      710\n",
       "newsr.in                                   488\n",
       "yahoo                                      391\n",
       "financialexpress.com                       343\n",
       "TV Guide                                   324\n",
       "wtopstaff                                  158\n",
       "The Associated Press                       148\n",
       "timesofindia.indiatimes.com                125\n",
       "AceShowbiz.com                             121\n",
       "chron.com                                  115\n",
       "IANS                                       112\n",
       "prbuzz.com                                 109\n",
       "Associated Press                           104\n",
       "Bloomberg.com                               93\n",
       "NEW YORK DAILY NEWS                         93\n",
       "morningstar.com                             89\n",
       "PRNW                                        84\n",
       "timesunion.com                              83\n",
       "wcax.com                                    77\n",
       "Post to Linkedin                            70\n",
       "tribuneindia.com                            68\n",
       "abcNEWS                                     57\n",
       "english.ahram.org.eg                        57\n",
       "Chris Kerins                                55\n",
       "dailycaller                                 53\n",
       "Tribune wire reports                        53\n",
       "                                         ...  \n",
       "AT&amp;T Inc.                                1\n",
       "IPG Mediabrands                              1\n",
       "Michael Schulman                             1\n",
       "Chris Taylor                                 1\n",
       "Priscilla Malinga                            1\n",
       "Diana Sroka Rickert                          1\n",
       "Julia Sayers | jsayers@al.com                1\n",
       "LAURA BLASEY                                 1\n",
       "Leah Fein-Roque                              1\n",
       "Jordan Honeycutt                             1\n",
       "COLLIN BINKLEY Associated Press              1\n",
       "Motown                                       1\n",
       "Beth Pinsker                                 1\n",
       "Michele Altman                               1\n",
       "Bradley Arant Boult Cummings LLP             1\n",
       "Michael Liedtke, AP Technology Writer        1\n",
       "Juro Osawa                                   1\n",
       "Gary Bedore                                  1\n",
       "The Peninsula Qatar                          1\n",
       "Mark Scott                                   1\n",
       "Dan Rule                                     1\n",
       "Tom Warren                                   1\n",
       "Ira Basen                                    1\n",
       "Mark Flaherty                                1\n",
       "MARK DIDTLER                                 1\n",
       "JERE HESTER                                  1\n",
       "Richard Broinowski                           1\n",
       "Nupur Anand                                  1\n",
       "Greg Braxton                                 1\n",
       "Lananh Nguyen                                1\n",
       "Name: source, Length: 4778, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from os import listdir\n",
    "\n",
    "df = pd.DataFrame(columns=['source'])\n",
    "\n",
    "financeArticles = listdir(\"DATA/Finance\")\n",
    "for index, article in enumerate(financeArticles, start=0):\n",
    "    if index < 8000 :\n",
    "        with open(\"DATA/Finance/\" + article, encoding=\"utf8\") as json_data:\n",
    "            author = json.load(json_data)[\"author\"]\n",
    "            df = df.append({'source': author}, ignore_index=True)  \n",
    "        with open(\"DATA/Sports/\" + article, encoding=\"utf8\") as json_data:\n",
    "            author = json.load(json_data)[\"author\"]\n",
    "            df = df.append({'source': author}, ignore_index=True)  \n",
    "        with open(\"DATA/Technology/\" + article, encoding=\"utf8\") as json_data:\n",
    "            author = json.load(json_data)[\"author\"]\n",
    "            df = df.append({'source': author}, ignore_index=True)  \n",
    "        with open(\"DATA/Entertainment/\" + article, encoding=\"utf8\") as json_data:\n",
    "            author = json.load(json_data)[\"author\"]\n",
    "            df = df.append({'source': author}, ignore_index=True)  \n",
    "        if( index % 250 == 0):\n",
    "            print(index)\n",
    "\n",
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.source.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING 1. RUN\n",
      "Preprocessed texts: 0\n",
      "Preprocessed texts: 250\n",
      "Preprocessed texts: 500\n",
      "Preprocessed texts: 750\n",
      "Preprocessed texts: 1000\n",
      "Preprocessed texts: 1250\n",
      "Preprocessed texts: 1500\n",
      "Preprocessed texts: 1750\n",
      "Preprocessed texts: 2000\n",
      "Preprocessed texts: 2250\n",
      "Preprocessed texts: 2500\n",
      "Preprocessed texts: 2750\n",
      "Preprocessed texts: 3000\n",
      "Preprocessed texts: 3250\n",
      "Preprocessed texts: 3500\n",
      "Preprocessed texts: 3750\n",
      "Preprocessed texts: 4000\n",
      "Preprocessed texts: 4250\n",
      "Preprocessed texts: 4500\n",
      "Preprocessed texts: 4750\n",
      "Preprocessed texts: 5000\n",
      "Preprocessed texts: 5250\n",
      "Preprocessed texts: 5500\n",
      "Preprocessed texts: 5750\n",
      "STARTING PREDICITION\n",
      "Predicted values: 0\n",
      "Predicted values: 250\n",
      "Predicted values: 500\n",
      "Predicted values: 750\n",
      "Predicted values: 1000\n",
      "Predicted values: 1250\n",
      "Predicted values: 1500\n",
      "Predicted values: 1750\n",
      "CALCULATIONG ACCURACY\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "0.5615\n",
      "STARTING 2. RUN\n",
      "Preprocessed texts: 0\n",
      "Preprocessed texts: 250\n",
      "Preprocessed texts: 500\n",
      "Preprocessed texts: 750\n",
      "Preprocessed texts: 1000\n",
      "Preprocessed texts: 1250\n",
      "Preprocessed texts: 1500\n",
      "Preprocessed texts: 1750\n",
      "Preprocessed texts: 2000\n",
      "Preprocessed texts: 2250\n",
      "Preprocessed texts: 2500\n",
      "Preprocessed texts: 2750\n",
      "Preprocessed texts: 3000\n",
      "Preprocessed texts: 3250\n",
      "Preprocessed texts: 3500\n",
      "Preprocessed texts: 3750\n",
      "Preprocessed texts: 4000\n",
      "Preprocessed texts: 4250\n",
      "Preprocessed texts: 4500\n",
      "Preprocessed texts: 4750\n",
      "Preprocessed texts: 5000\n",
      "Preprocessed texts: 5250\n",
      "Preprocessed texts: 5500\n",
      "Preprocessed texts: 5750\n",
      "STARTING PREDICITION\n",
      "Predicted values: 0\n",
      "Predicted values: 250\n",
      "Predicted values: 500\n",
      "Predicted values: 750\n",
      "Predicted values: 1000\n",
      "Predicted values: 1250\n",
      "Predicted values: 1500\n",
      "Predicted values: 1750\n",
      "CALCULATIONG ACCURACY\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "Accuracy calculated for: 1999\n",
      "0.5615\n",
      "STARTING 3. RUN\n",
      "Preprocessed texts: 0\n",
      "Preprocessed texts: 250\n",
      "Preprocessed texts: 500\n",
      "Preprocessed texts: 750\n",
      "Preprocessed texts: 1000\n",
      "Preprocessed texts: 1250\n",
      "Preprocessed texts: 1500\n",
      "Preprocessed texts: 1750\n",
      "Preprocessed texts: 2000\n",
      "Preprocessed texts: 2250\n",
      "Preprocessed texts: 2500\n",
      "Preprocessed texts: 2750\n",
      "Preprocessed texts: 3000\n",
      "Preprocessed texts: 3250\n",
      "Preprocessed texts: 3500\n",
      "Preprocessed texts: 3750\n",
      "Preprocessed texts: 4000\n",
      "Preprocessed texts: 4250\n",
      "Preprocessed texts: 4500\n",
      "Preprocessed texts: 4750\n",
      "Preprocessed texts: 5000\n",
      "Preprocessed texts: 5250\n",
      "Preprocessed texts: 5500\n",
      "Preprocessed texts: 5750\n",
      "STARTING PREDICITION\n",
      "Predicted values: 0\n",
      "Predicted values: 250\n",
      "Predicted values: 500\n",
      "Predicted values: 750\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rawTexts =  gatherTexts(1,2000,np.array([0,1,2,3]))\n",
    "results = []\n",
    "\n",
    "print(\"STARTING 1. RUN\")\n",
    "\n",
    "regs = compileRegexes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawTexts['texts'], rawTexts['types'], random_state = 0)\n",
    "\n",
    "preprocessedTexts = preprocessTexts(X_train,y_train,regs,1)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "print(\"STARTING PREDICITION\")\n",
    "predicted = []\n",
    "for index, article in enumerate(X_test, start=0):\n",
    "    predicted.append(predict(phi,article,preprocessedTexts[\"words\"],regs,0))\n",
    "    if( index % 250 == 0):\n",
    "            print(\"Predicted values:\", index)\n",
    "print(\"CALCULATIONG ACCURACY\")\n",
    "succes = 0\n",
    "for ind in range(0, len(predicted)):\n",
    "    if predicted[ind] == int(y_test[ind]):\n",
    "        succes = succes + 1\n",
    "    if( ind % 250 == 0):\n",
    "            print(\"Accuracy calculated for:\", index)\n",
    "        \n",
    "print(succes/len(y_test))\n",
    "results.append(succes/len(y_test))\n",
    "\n",
    "\n",
    "print(\"STARTING 2. RUN\")\n",
    "\n",
    "regs = compileRegexes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawTexts['texts'], rawTexts['types'], random_state = 0)\n",
    "\n",
    "preprocessedTexts = preprocessTexts(X_train,y_train,regs,1)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "print(\"STARTING PREDICITION\")\n",
    "predicted = []\n",
    "for index, article in enumerate(X_test, start=0):\n",
    "    predicted.append(predict(phi,article,preprocessedTexts[\"words\"],regs,0))\n",
    "    if( index % 250 == 0):\n",
    "            print(\"Predicted values:\", index)\n",
    "print(\"CALCULATIONG ACCURACY\")\n",
    "succes = 0\n",
    "for ind in range(0, len(predicted)):\n",
    "    if predicted[ind] == int(y_test[ind]):\n",
    "        succes = succes + 1\n",
    "    if( ind % 250 == 0):\n",
    "            print(\"Accuracy calculated for:\", index)\n",
    "        \n",
    "print(succes/len(y_test))\n",
    "results.append(succes/len(y_test))\n",
    "\n",
    "\n",
    "print(\"STARTING 3. RUN\")\n",
    "\n",
    "regs = compileRegexes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawTexts['texts'], rawTexts['types'], random_state = 0)\n",
    "\n",
    "preprocessedTexts = preprocessTexts(X_train,y_train,regs,1)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "print(\"STARTING PREDICITION\")\n",
    "predicted = []\n",
    "for index, article in enumerate(X_test, start=0):\n",
    "    predicted.append(predict(phi,article,preprocessedTexts[\"words\"],regs,0))\n",
    "    if( index % 250 == 0):\n",
    "            print(\"Predicted values:\", index)\n",
    "print(\"CALCULATIONG ACCURACY\")\n",
    "succes = 0\n",
    "for ind in range(0, len(predicted)):\n",
    "    if predicted[ind] == int(y_test[ind]):\n",
    "        succes = succes + 1\n",
    "    if( ind % 250 == 0):\n",
    "            print(\"Accuracy calculated for:\", index)\n",
    "        \n",
    "print(succes/len(y_test))\n",
    "results.append(succes/len(y_test))\n",
    "\n",
    "\n",
    "print(\"STARTING 4. RUN\")\n",
    "\n",
    "regs = compileRegexes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawTexts['texts'], rawTexts['types'], random_state = 0)\n",
    "\n",
    "preprocessedTexts = preprocessTexts(X_train,y_train,regs,1)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "print(\"STARTING PREDICITION\")\n",
    "predicted = []\n",
    "for index, article in enumerate(X_test, start=0):\n",
    "    predicted.append(predict(phi,article,preprocessedTexts[\"words\"],regs,0))\n",
    "    if( index % 250 == 0):\n",
    "            print(\"Predicted values:\", index)\n",
    "print(\"CALCULATIONG ACCURACY\")\n",
    "succes = 0\n",
    "for ind in range(0, len(predicted)):\n",
    "    if predicted[ind] == int(y_test[ind]):\n",
    "        succes = succes + 1\n",
    "    if( ind % 250 == 0):\n",
    "            print(\"Accuracy calculated for:\", index)\n",
    "        \n",
    "print(succes/len(y_test))\n",
    "results.append(succes/len(y_test))\n",
    "\n",
    "\n",
    "print(\"STARTING 5. RUN\")\n",
    "\n",
    "regs = compileRegexes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(rawTexts['texts'], rawTexts['types'], random_state = 0)\n",
    "\n",
    "preprocessedTexts = preprocessTexts(X_train,y_train,regs,1)\n",
    "phi = createPhiMatrix(preprocessedTexts[\"articleWords\"],np.array([0,1,2,3]))\n",
    "print(\"STARTING PREDICITION\")\n",
    "predicted = []\n",
    "for index, article in enumerate(X_test, start=0):\n",
    "    predicted.append(predict(phi,article,preprocessedTexts[\"words\"],regs,0))\n",
    "    if( index % 250 == 0):\n",
    "            print(\"Predicted values:\", index)\n",
    "print(\"CALCULATIONG ACCURACY\")\n",
    "succes = 0\n",
    "for ind in range(0, len(predicted)):\n",
    "    if predicted[ind] == int(y_test[ind]):\n",
    "        succes = succes + 1\n",
    "    if( ind % 250 == 0):\n",
    "            print(\"Accuracy calculated for:\", index)\n",
    "        \n",
    "print(succes/len(y_test))\n",
    "results.append(succes/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '3',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '3',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '3']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
